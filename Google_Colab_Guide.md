# üöÄ H∆Ø·ªöNG D·∫™N CH·∫†Y PROJECT TR√äN GOOGLE COLAB

## üìã T·ªïng quan
H∆∞·ªõng d·∫´n chi ti·∫øt ƒë·ªÉ ch·∫°y project **Telco Customer Churn Prediction** tr√™n Google Colab m·ªôt c√°ch ƒë∆°n gi·∫£n v√† hi·ªáu qu·∫£.

## ‚ö° ∆Øu ƒëi·ªÉm c·ªßa Google Colab
- ‚úÖ **Mi·ªÖn ph√≠** v√† c√≥ GPU/TPU
- ‚úÖ **Kh√¥ng c·∫ßn c√†i ƒë·∫∑t** g√¨ tr√™n m√°y t√≠nh
- ‚úÖ **ƒê√£ c√≥ s·∫µn** t·∫•t c·∫£ th∆∞ vi·ªán c·∫ßn thi·∫øt
- ‚úÖ **D·ªÖ chia s·∫ª** v√† collaborate
- ‚úÖ **L∆∞u tr·ªØ tr√™n Google Drive**

## üîß B∆∞·ªõc 1: Chu·∫©n b·ªã

### 1.1 T·∫°o Google Colab Notebook
1. Truy c·∫≠p [Google Colab](https://colab.research.google.com/)
2. ƒêƒÉng nh·∫≠p t√†i kho·∫£n Google
3. T·∫°o notebook m·ªõi: **File > New notebook**

### 1.2 Upload d·ªØ li·ªáu
```python
import pandas as pd
# N·∫øu c√≥ link download tr·ª±c ti·∫øp
url = "https://raw.githubusercontent.com/tanmaiii/may_hoc_ung_dung/refs/heads/main/telco-customer-churn.csv"
df = pd.read_csv(url)
```

## üìä B∆∞·ªõc 2: Notebook ho√†n ch·ªânh

### 2.1 Setup v√† Import Libraries
```python
# C√†i ƒë·∫∑t th√™m packages n·∫øu c·∫ßn
!pip install plotly seaborn

# Import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# Machine Learning
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler
from sklearn.feature_selection import SelectKBest, f_classif, RFE
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve

# T·∫Øt warnings
import warnings
warnings.filterwarnings('ignore')

# C√†i ƒë·∫∑t style cho plots
plt.style.use('default')
sns.set_palette("husl")
```

### 2.2 Load v√† Explore Data (Load d·ªØ li·ªáu)
```python
# Load data
df = pd.read_csv('telco-customer-churn.csv')  # Ho·∫∑c ƒë∆∞·ªùng d·∫´n file b·∫°n upload

print("üéØ T·ªîNG QUAN D·ªÆ LI·ªÜU")
print(f"K√≠ch th∆∞·ªõc: {df.shape}")
print(f"Gi√° tr·ªã thi·∫øu: {df.isnull().sum().sum()}")
print("\nüìä 5 d√≤ng ƒë·∫ßu ti√™n:")
df.head()
```

### 2.3 Data Analysis v√† Visualization (Ph√¢n t√≠ch d·ªØ li·ªáu v√† tr·ª±c quan h√≥a)
```python
# Basic info
print("üìà TH√îNG TIN D·ªÆ LI·ªÜU")
df.info()

print("\nüìä TH·ªêNG K√ä M√î T·∫¢")
df.describe()

# Churn distribution
print("\nüéØ PH√ÇN B·ªê CHURN")
churn_counts = df['Churn'].value_counts()
print(churn_counts)
print(f"T·ª∑ l·ªá kh√°ch h√†ng r·ªùi b·ªè d·ªãch v·ª• (Churn rate): {churn_counts[1] / len(df) * 100:.2f}%")

# Visualization
fig, axes = plt.subplots(2, 2, figsize=(15, 10))

# Bi·ªÉu ƒë·ªì pie char
axes[0,0].pie(churn_counts.values, labels=churn_counts.index, autopct='%1.1f%%')
axes[0,0].set_title('T·ª∑ l·ªá kh√°ch h√†ng r·ªùi b·ªè (Churn)')

# Bi·ªÉu ƒë·ªì Histogram
axes[0,1].hist(df['tenure'], bins=30, alpha=0.7)
axes[0,1].set_title('Ph√¢n b·ªë th·ªùi gian s·ª≠ d·ª•ng')
axes[0,1].set_xlabel('S·ªë th√°ng s·ª≠ d·ª•ng (tenure)')

# Bi·ªÉu ƒë·ªì Boxplot
sns.boxplot(data=df, x='Churn', y='MonthlyCharges', ax=axes[1,0])
axes[1,0].set_title('Chi ph√≠ h√†ng th√°ng theo Churn')

# Bi·ªÉu ƒë·ªì Bar chart
contract_churn = pd.crosstab(df['Contract'], df['Churn'])
contract_churn.plot(kind='bar', ax=axes[1,1])
axes[1,1].set_title('Lo·∫°i h·ª£p ƒë·ªìng v√† Churn')
axes[1,1].legend(title='Churn')

plt.tight_layout()
plt.show()
```

## üîÑ B∆∞·ªõc 3: Data Preprocessing (Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu)

### 3.1 Data Cleaning (L√†m s·∫°ch)
```python
# T·∫°o copy ƒë·ªÉ x·ª≠ l√Ω
df_clean = df.copy()

print("üßπ L√ÄM S·∫†CH D·ªÆ LI·ªÜU...")

# X·ª≠ l√Ω TotalCharges (c√≥ gi√° tr·ªã ' ')
print(f"Gi√° tr·ªã ' ' trong TotalCharges: {(df_clean['TotalCharges'] == ' ').sum()}")
df_clean['TotalCharges'] = df_clean['TotalCharges'].replace(' ', np.nan)
df_clean['TotalCharges'] = pd.to_numeric(df_clean['TotalCharges'], errors='coerce')

# Fill missing values
df_clean['TotalCharges'].fillna(0, inplace=True)

# Remove customerID
df_clean = df_clean.drop('customerID', axis=1)

print(f"‚úÖ K√≠ch th∆∞·ªõc sau l√†m s·∫°ch: {df_clean.shape}")
print(f"Gi√° tr·ªã thi·∫øu sau l√†m s·∫°ch: {df_clean.isnull().sum().sum()}")
```

### 3.2 Feature Engineering 
```python
print("üîß T·∫†O ƒê·∫∂C TR∆ØNG M·ªöI...")

# Binary encoding cho Yes/No columns
binary_cols = []
for col in df_clean.columns:
    if df_clean[col].dtype == 'object' and col != 'Churn':
        unique_vals = df_clean[col].unique()
        if set(unique_vals).issubset({'Yes', 'No'}):
            binary_cols.append(col)
            df_clean[col] = df_clean[col].map({'Yes': 1, 'No': 0})

print(f"C√°c c·ªôt ƒë√£ m√£ h√≥a nh·ªã ph√¢n: {binary_cols}")

# One-hot encoding cho nominal variables
nominal_cols = ['gender', 'Contract', 'PaymentMethod', 'InternetService']
df_encoded = pd.get_dummies(df_clean, columns=nominal_cols, drop_first=True)

# Encode target variable
df_encoded['Churn'] = df_encoded['Churn'].map({'Yes': 1, 'No': 0})

# Create new features
df_encoded['AvgChargePerTenure'] = np.where(
    df_encoded['tenure'] > 0,
    df_encoded['TotalCharges'] / df_encoded['tenure'],
    df_encoded['MonthlyCharges']
)

# Tenure groups - t·∫°o nh√≥m theo th·ªùi gian s·ª≠ d·ª•ng
try:
    df_encoded['TenureGroup'] = pd.cut(
        df_encoded['tenure'],
        bins=[0, 12, 36, 60, float('inf')],
        labels=['0-12m', '13-36m', '37-60m', '60m+']
    )
    # Encode categorical labels th√†nh s·ªë
    df_encoded['TenureGroup'] = df_encoded['TenureGroup'].cat.codes
except Exception as e:
    print(f"L·ªói khi t·∫°o TenureGroup: {e}")
    # Fallback: t·∫°o nh√≥m ƒë∆°n gi·∫£n
    df_encoded['TenureGroup'] = pd.cut(
        df_encoded['tenure'],
        bins=4,
        labels=[0, 1, 2, 3]
    ).astype(int)

print(f"‚úÖ K√≠ch th∆∞·ªõc cu·ªëi c√πng: {df_encoded.shape}")
df_encoded.head()
```

## üéØ B∆∞·ªõc 4: Feature Selection

### 4.1 Correlation Analysis
```python
# Correlation heatmap
plt.figure(figsize=(20, 16))
correlation_matrix = df_encoded.corr()
sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', center=0)
plt.title('Ma tr·∫≠n t∆∞∆°ng quan ƒë·∫∑c tr∆∞ng')
plt.show()

# Top correlations with target
target_corr = correlation_matrix['Churn'].abs().sort_values(ascending=False)
print("üéØ TOP 15 ƒê·∫∂C TR∆ØNG T∆Ø∆†NG QUAN V·ªöI CHURN:")
print(target_corr.head(15))
```

### 4.2 Feature Selection Methods
```python
# Prepare data
X = df_encoded.drop('Churn', axis=1)
y = df_encoded['Churn']

print(f"K√≠ch th∆∞·ªõc ƒë·∫∑c tr∆∞ng: {X.shape}")
print(f"Ph√¢n b·ªë target: {y.value_counts().to_dict()}")

# Method 1: SelectKBest
def select_features_univariate(X, y, k=10):
    selector = SelectKBest(score_func=f_classif, k=k)
    X_selected = selector.fit_transform(X, y)
    selected_features = X.columns[selector.get_support()].tolist()
    scores = selector.scores_
    
    feature_scores = pd.DataFrame({
        'feature': X.columns,
        'score': scores
    }).sort_values('score', ascending=False)
    
    return selected_features, feature_scores

# Method 2: Random Forest Feature Importance
def select_features_rf(X, y, k=10):
    rf = RandomForestClassifier(n_estimators=100, random_state=42)
    rf.fit(X, y)
    
    feature_importance = pd.DataFrame({
        'feature': X.columns,
        'importance': rf.feature_importances_
    }).sort_values('importance', ascending=False)
    
    selected_features = feature_importance.head(k)['feature'].tolist()
    return selected_features, feature_importance

# Apply feature selection
for k in [5, 10, 15]:
    print(f"\nüîç TOP {k} ƒê·∫∂C TR∆ØNG:")
    
    # Univariate selection
    features_uni, scores_uni = select_features_univariate(X, y, k)
    print(f"Ph∆∞∆°ng ph√°p Univariate: {features_uni}")
    
    # Random Forest
    features_rf, scores_rf = select_features_rf(X, y, k)
    print(f"Random Forest: {features_rf}")
```

## ü§ñ B∆∞·ªõc 5: Model Training v√† Evaluation

### 5.1 Data Splitting v√† Scaling
```python
# Split data
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Scaling
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print(f"T·∫≠p hu·∫•n luy·ªán: {X_train_scaled.shape}")
print(f"T·∫≠p ki·ªÉm tra: {X_test_scaled.shape}")
print(f"Ph√¢n b·ªë target trong t·∫≠p train: {y_train.value_counts(normalize=True).round(3).to_dict()}")
```

### 5.2 Model Training
```python
# Define models
models = {
    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),
    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),
    'SVM': SVC(random_state=42, probability=True)
}

# Train and evaluate models
results = {}

for name, model in models.items():
    print(f"\nüîÑ ƒêang hu·∫•n luy·ªán {name}...")
    
    # Train model
    model.fit(X_train_scaled, y_train)
    
    # Predictions
    y_pred = model.predict(X_test_scaled)
    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1] if hasattr(model, 'predict_proba') else None
    
    # Metrics
    accuracy = accuracy_score(y_test, y_pred)
    auc = roc_auc_score(y_test, y_pred_proba) if y_pred_proba is not None else None
    
    # Cross validation
    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='accuracy')
    
    results[name] = {
        'accuracy': accuracy,
        'auc': auc,
        'cv_mean': cv_scores.mean(),
        'cv_std': cv_scores.std(),
        'y_pred': y_pred,
        'y_pred_proba': y_pred_proba
    }
    
    print(f"   ƒê·ªô ch√≠nh x√°c: {accuracy:.4f}")
    print(f"   AUC: {auc:.4f}" if auc else "   AUC: Kh√¥ng c√≥")
    print(f"   CV Accuracy: {cv_scores.mean():.4f} (¬±{cv_scores.std():.4f})")
```

### 5.3 Results Visualization
```python
# Results comparison
results_df = pd.DataFrame({
    name: {
        'Test Accuracy': results[name]['accuracy'],
        'AUC Score': results[name]['auc'] if results[name]['auc'] else 0,
        'CV Mean': results[name]['cv_mean'],
        'CV Std': results[name]['cv_std']
    } for name in results.keys()
}).T

print("üìä SO S√ÅNH M√î H√åNH:")
print(results_df.round(4))

# Plot comparison
fig, axes = plt.subplots(1, 3, figsize=(18, 5))

# Accuracy comparison
results_df['Test Accuracy'].plot(kind='bar', ax=axes[0], color='skyblue')
axes[0].set_title('So s√°nh ƒë·ªô ch√≠nh x√°c ki·ªÉm tra')
axes[0].set_ylabel('ƒê·ªô ch√≠nh x√°c')
axes[0].tick_params(axis='x', rotation=45)

# AUC comparison
results_df['AUC Score'].plot(kind='bar', ax=axes[1], color='lightgreen')
axes[1].set_title('So s√°nh ƒëi·ªÉm AUC')
axes[1].set_ylabel('AUC')
axes[1].tick_params(axis='x', rotation=45)

# CV scores with error bars
cv_means = results_df['CV Mean']
cv_stds = results_df['CV Std']
axes[2].bar(range(len(cv_means)), cv_means, yerr=cv_stds, capsize=5, color='orange', alpha=0.7)
axes[2].set_title('ƒêi·ªÉm Cross Validation')
axes[2].set_ylabel('CV Accuracy')
axes[2].set_xticks(range(len(cv_means)))
axes[2].set_xticklabels(cv_means.index, rotation=45)

plt.tight_layout()
plt.show()

# Confusion matrices
fig, axes = plt.subplots(1, 3, figsize=(15, 4))
for i, (name, result) in enumerate(results.items()):
    cm = confusion_matrix(y_test, result['y_pred'])
    sns.heatmap(cm, annot=True, fmt='d', ax=axes[i], cmap='Blues')
    axes[i].set_title(f'{name}\nƒê·ªô ch√≠nh x√°c: {result["accuracy"]:.3f}')
    axes[i].set_xlabel('D·ª± ƒëo√°n')
    axes[i].set_ylabel('Th·ª±c t·∫ø')

plt.tight_layout()
plt.show()
```

## üéØ B∆∞·ªõc 6: Feature Selection Performance

### 6.1 Test v·ªõi Different Feature Sets
```python
# Test performance v·ªõi different feature sets
feature_sets = {
    'Top 5 Univariate': select_features_univariate(X, y, 5)[0],
    'Top 10 Univariate': select_features_univariate(X, y, 10)[0],
    'Top 15 Univariate': select_features_univariate(X, y, 15)[0],
    'Top 5 RF': select_features_rf(X, y, 5)[0],
    'Top 10 RF': select_features_rf(X, y, 10)[0],
    'Top 15 RF': select_features_rf(X, y, 15)[0],
}

# Performance v·ªõi feature subsets
subset_results = {}

for subset_name, features in feature_sets.items():
    print(f"\nüîç ƒêang ki·ªÉm tra {subset_name} ({len(features)} ƒë·∫∑c tr∆∞ng)...")
    
    # Subset data
    X_subset = X[features]
    X_train_sub, X_test_sub, y_train_sub, y_test_sub = train_test_split(
        X_subset, y, test_size=0.2, random_state=42, stratify=y
    )
    
    # Scale
    X_train_sub_scaled = scaler.fit_transform(X_train_sub)
    X_test_sub_scaled = scaler.transform(X_test_sub)
    
    # Train best model (Random Forest)
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X_train_sub_scaled, y_train_sub)
    
    # Evaluate
    y_pred_sub = model.predict(X_test_sub_scaled)
    accuracy_sub = accuracy_score(y_test_sub, y_pred_sub)
    
    subset_results[subset_name] = {
        'n_features': len(features),
        'accuracy': accuracy_sub,
        'features': features
    }
    
    print(f"   ƒê·ªô ch√≠nh x√°c: {accuracy_sub:.4f} v·ªõi {len(features)} ƒë·∫∑c tr∆∞ng")

# Plot feature selection results
subset_df = pd.DataFrame(subset_results).T
subset_df = subset_df.sort_values('accuracy', ascending=False)

plt.figure(figsize=(12, 6))
bars = plt.bar(range(len(subset_df)), subset_df['accuracy'], color='lightcoral')
plt.xlabel('Ph∆∞∆°ng ph√°p l·ª±a ch·ªçn ƒë·∫∑c tr∆∞ng')
plt.ylabel('ƒê·ªô ch√≠nh x√°c')
plt.title('Hi·ªáu su·∫•t theo ph∆∞∆°ng ph√°p l·ª±a ch·ªçn ƒë·∫∑c tr∆∞ng')
plt.xticks(range(len(subset_df)), subset_df.index, rotation=45)

# Add value labels on bars
for i, bar in enumerate(bars):
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2., height + 0.005,
             f'{height:.3f}\n({subset_df.iloc[i]["n_features"]} ƒë·∫∑c tr∆∞ng)',
             ha='center', va='bottom')

plt.tight_layout()
plt.show()

print("\nüèÜ K·∫æT QU·∫¢ CH·ªåN ƒê·∫∂C TR∆ØNG T·ªêT NH·∫§T:")
print(subset_df.sort_values('accuracy', ascending=False))
```

## üíæ B∆∞·ªõc 7: Save Results

### 7.1 Export Results
```python
# Save results to CSV
results_df.to_csv('model_comparison_results.csv')
subset_df.to_csv('feature_selection_results.csv')

# Download files
from google.colab import files
files.download('model_comparison_results.csv')
files.download('feature_selection_results.csv')

print("‚úÖ K·∫øt qu·∫£ ƒë√£ ƒë∆∞·ª£c l∆∞u v√† t·∫£i xu·ªëng!")
```

## üéâ Ho√†n th√†nh!

### üìä Summary
```python
print("üéØ T√ìM T·∫ÆT D·ª∞ √ÅN")
print("=" * 50)
print(f"üìä D·ªØ li·ªáu: {df.shape[0]} kh√°ch h√†ng, {df.shape[1]} ƒë·∫∑c tr∆∞ng")
print(f"üéØ M·ª•c ti√™u: Customer Churn ({(y.sum() / len(y) * 100):.1f}% t·ª∑ l·ªá churn)")
print(f"üîß ƒê·∫∑c tr∆∞ng sau ti·ªÅn x·ª≠ l√Ω: {X.shape[1]}")
print(f"üèÜ M√¥ h√¨nh t·ªët nh·∫•t: {results_df['Test Accuracy'].idxmax()} ({results_df['Test Accuracy'].max():.3f})")
print(f"üéØ B·ªô ƒë·∫∑c tr∆∞ng t·ªët nh·∫•t: {subset_df.index[0]} ({subset_df.iloc[0]['accuracy']:.3f})")
print("\n‚úÖ Ph√¢n t√≠ch ho√†n th√†nh th√†nh c√¥ng!")
```

## üöÄ Tips cho Google Colab

### T·ªëi ∆∞u Performance:
- S·ª≠ d·ª•ng GPU: **Runtime > Change runtime type > GPU**
- Disconnect sau khi xong: **Runtime > Disconnect**
- Restart n·∫øu memory ƒë·∫ßy: **Runtime > Restart runtime**

### L∆∞u tr·ªØ:
- Mount Google Drive ƒë·ªÉ l∆∞u permanent
- Download results quan tr·ªçng v·ªÅ m√°y
- Copy notebook v√†o Drive ƒë·ªÉ backup

### Troubleshooting:
- N·∫øu b·ªã disconnect: Re-run t·ª´ ƒë·∫ßu
- N·∫øu thi·∫øu package: `!pip install package_name`
- N·∫øu l·ªói memory: Gi·∫£m data size ho·∫∑c d√πng sampling

---

**üéâ Ch√∫c b·∫°n th√†nh c√¥ng v·ªõi project Machine Learning!** 