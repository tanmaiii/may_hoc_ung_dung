# K·∫ø Ho·∫°ch D·ª± √Ån Machine Learning - Telco Customer Churn

## üéØ M·ª•c ti√™u D·ª± √°n

### M·ª•c ti√™u ch√≠nh:
1. **Gi·∫£i quy·∫øt b√†i to√°n** s·ª≠ d·ª•ng h·ªçc m√°y ƒë·ªÉ d·ª± ƒëo√°n customer churn
2. **T√¨m hi·ªÉu c√°c m√¥ h√¨nh** h·ªçc m√°y c√≥ th·ªÉ gi·∫£i quy·∫øt b√†i to√°n
3. **ƒê√°nh gi√°, so s√°nh hi·ªáu qu·∫£** c·ªßa c√°c m√¥ h√¨nh
4. **N√¢ng cao hi·ªáu qu·∫£** c·ªßa m√¥ h√¨nh th√¥ng qua optimization

### K·∫øt qu·∫£ mong ƒë·ª£i:
- M√¥ h√¨nh d·ª± ƒëo√°n churn v·ªõi accuracy > 80%
- So s√°nh hi·ªáu su·∫•t c·ªßa √≠t nh·∫•t 5 thu·∫≠t to√°n kh√°c nhau
- Feature selection t·ªëi ∆∞u (top 5, 10, 15 features)
- Hyperparameter tuning cho m√¥ h√¨nh t·ªët nh·∫•t

## üìã B∆∞·ªõc Th·ª±c Hi·ªán Chi Ti·∫øt

### 1. X√°c ƒë·ªãnh B√†i to√°n
- **Lo·∫°i b√†i to√°n**: Binary Classification
- **Target variable**: Churn (Yes/No)
- **Metrics ƒë√°nh gi√°**: Accuracy, Precision, Recall, F1-Score, AUC-ROC

### 2. Thu th·∫≠p D·ªØ li·ªáu
- ‚úÖ **Dataset**: `telco-customer-churn.csv` (7,043 records, 21 features)
- **Ngu·ªìn**: Kaggle/IBM Watson Analytics
- **K√≠ch th∆∞·ªõc**: 955KB

### 3. Ti·ªÅn x·ª≠ l√Ω D·ªØ li·ªáu
- **Data cleaning**: Missing values, outliers
- **Data transformation**: Encoding categorical variables
- **Feature engineering**: T·∫°o features m·ªõi t·ª´ existing data
- **Data scaling**: StandardScaler, MinMaxScaler

### 4. Th·ªëng k√™ M√¥ t·∫£ D·ªØ li·ªáu (EDA)
- **Univariate analysis**: Distribution c·ªßa t·ª´ng feature
- **Bivariate analysis**: Relationship gi·ªØa features v√† target
- **Multivariate analysis**: Correlation matrix
- **Data visualization**: Charts, plots, heatmaps

### 5. L·ª±a ch·ªçn M√¥ h√¨nh
- **Baseline models**: Logistic Regression, Decision Tree
- **Advanced models**: Random Forest, XGBoost, SVM
- **Deep learning**: Neural Networks
- **Ensemble methods**: Voting, Stacking

### 6. Hu·∫•n luy·ªán v√† Ki·ªÉm th·ª≠
- **Train/Validation/Test split**: 70/15/15
- **Cross validation**: 5-fold CV
- **Model training**: Fit c√°c m√¥ h√¨nh
- **Model evaluation**: Metrics comparison

### 7. ƒê√°nh gi√° v√† So s√°nh
- **Performance metrics**: Confusion matrix, ROC curve
- **Model comparison**: Accuracy, Speed, Interpretability
- **Statistical testing**: Paired t-test for model comparison

## üóìÔ∏è Timeline D·ª± Ki·∫øn

| Tu·∫ßn | C√¥ng vi·ªác | Deliverables |
|------|-----------|--------------|
| 1 | Data Exploration & Preprocessing | EDA notebook, cleaned data |
| 2 | Feature Engineering & Selection | Feature matrix, selection results |
| 3 | Model Training & Initial Evaluation | Baseline models, initial metrics |
| 4 | Hyperparameter Tuning & Advanced Models | Optimized models |
| 5 | Final Evaluation & Reporting | Final report, model comparison |

## üìä Metrics ƒê√°nh Gi√°

### Primary Metrics:
- **Accuracy**: T·ª∑ l·ªá d·ª± ƒëo√°n ƒë√∫ng
- **Precision**: Trong s·ªë d·ª± ƒëo√°n churn, bao nhi·ªÅu % th·ª±c s·ª± churn
- **Recall**: Trong s·ªë th·ª±c s·ª± churn, bao nhi·ªÅu % ƒë∆∞·ª£c d·ª± ƒëo√°n ƒë√∫ng
- **F1-Score**: Harmonic mean c·ªßa Precision v√† Recall

### Secondary Metrics:
- **AUC-ROC**: Area Under ROC Curve
- **Confusion Matrix**: Chi ti·∫øt v·ªÅ c√°c lo·∫°i l·ªói
- **Training Time**: Th·ªùi gian training
- **Prediction Time**: Th·ªùi gian inference

## üéØ Success Criteria

1. **Model Performance**: Accuracy ‚â• 80%, F1-Score ‚â• 0.75
2. **Feature Selection**: ƒê·∫°t performance t·ªët v·ªõi ‚â§ 15 features
3. **Model Comparison**: So s√°nh √≠t nh·∫•t 5 algorithms kh√°c nhau
4. **Optimization**: C·∫£i thi·ªán baseline model √≠t nh·∫•t 5%
5. **Documentation**: Complete notebooks v√† reports

## üöÄ Next Steps

1. **Setup environment**: Install required packages
2. **Create project structure**: Folders v√† files
3. **Start with EDA**: Exploratory Data Analysis
4. **Implement preprocessing pipeline**
5. **Begin model experimentation**

---

**Let's build an amazing ML project! üéâ** 